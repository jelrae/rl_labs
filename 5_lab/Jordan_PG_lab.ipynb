{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning - Policy Gradient\n",
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the pg_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports %%execwritefile command (executes cell and writes it into file). \n",
    "from custommagics import CustomMagics\n",
    "get_ipython().register_magics(CustomMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pg_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile pg_autograde.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm as _tqdm\n",
    "\n",
    "def tqdm(*args, **kwargs):\n",
    "    return _tqdm(*args, **kwargs, mininterval=1)  # Safety, do not overflow buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc69f22067705372",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "import time\n",
    "\n",
    "assert sys.version_info[:3] >= (3, 6, 0), \"Make sure you have Python 3.6 installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6607b79e73a101a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76a10fe31897025f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 3.1 Policy Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34f0712f792bbcca",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In order to implement policy gradient, we will first implement a class with a policy network. Although in general this does not have to be the case, we will use an architecture very similar to the Q-network that we used (two layers with ReLU activation for the hidden layer). Since we have discrete actions, our model will output one value per action, where each value represents the (normalized!) probability of selecting that action. *Use the softmax activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a31440f9477f963",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to pg_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a pg_autograde.py\n",
    "\n",
    "class NNPolicy(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_hidden=128):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = nn.Linear(4, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: input tensor (first dimension is a batch dimension)\n",
    "            \n",
    "        Return:\n",
    "            Probabilities of performing all actions in given input states x. Shape: batch_size x action_space_size\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return nn.functional.softmax(self.l2(nn.functional.relu(self.l1(x))), dim = -1)\n",
    "        \n",
    "    def get_probs(self, obs, actions):\n",
    "        \"\"\"\n",
    "        This function takes a tensor of states and a tensor of actions and returns a tensor that contains \n",
    "        a probability of perfoming corresponding action in all states (one for every state action pair). \n",
    "\n",
    "        Args:\n",
    "            obs: a tensor of states. Shape: batch_size x obs_dim\n",
    "            actions: a tensor of actions. Shape: batch_size x 1\n",
    "\n",
    "        Returns:\n",
    "            A torch tensor filled with probabilities. Shape: batch_size x 1.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "#         with  torch.no_grad():\n",
    "        probs = self.forward(obs)\n",
    "        action_probs = probs.gather(-1, actions).float()\n",
    "        \n",
    "        return action_probs\n",
    "    \n",
    "    def sample_action(self, obs):\n",
    "        \"\"\"\n",
    "        This method takes a state as input and returns an action sampled from this policy.  \n",
    "\n",
    "        Args:\n",
    "            obs: state as a tensor. Shape: 1 x obs_dim or obs_dim\n",
    "\n",
    "        Returns:\n",
    "            An action (int).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "#         obs = torch.tensor(obs)\n",
    "#         with torch.no_grad():\n",
    "        probs = self.forward(obs)\n",
    "    \n",
    "        action = torch.multinomial(probs, 1).item()\n",
    "#         print(\"We sampling\", action)\n",
    "        return action\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d280fe6520edc91",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0]])\n",
      "tensor([[0.4578, 0.5422],\n",
      "        [0.4657, 0.5343],\n",
      "        [0.4563, 0.5437],\n",
      "        [0.4634, 0.5366],\n",
      "        [0.4564, 0.5436],\n",
      "        [0.4725, 0.5275],\n",
      "        [0.4769, 0.5231],\n",
      "        [0.4834, 0.5166],\n",
      "        [0.4797, 0.5203],\n",
      "        [0.4618, 0.5382]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.4578],\n",
      "        [0.5343],\n",
      "        [0.5437],\n",
      "        [0.4634],\n",
      "        [0.4564],\n",
      "        [0.5275],\n",
      "        [0.4769],\n",
      "        [0.5166],\n",
      "        [0.4797],\n",
      "        [0.4618]], grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Let's instantiate and test if it works\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "policy = NNPolicy(num_hidden)\n",
    "\n",
    "states = torch.rand(10, 4)\n",
    "actions = torch.randint(low=0, high=2, size=(10,1))\n",
    "print(actions)\n",
    "\n",
    "# Does the outcome make sense?\n",
    "forward_probs = policy.forward(states)\n",
    "print(forward_probs)\n",
    "assert forward_probs.shape == (10,2), \"Output of forward has incorrect shape.\"\n",
    "sampled_action = policy.sample_action(states[0])\n",
    "assert sampled_action == 0 or sampled_action == 1, \"Output of sample action is not 0 or 1\"\n",
    "\n",
    "action_probs = policy.get_probs(states, actions)\n",
    "print(action_probs)\n",
    "assert action_probs.shape == (10,1), \"Output of get_probs has incorrect shape.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Monte Carlo REINFORCE\n",
    "\n",
    "Now we will implement the *Monte Carlo* policy gradient algorithm. Remember that this means that we will estimate returns for states by sample episodes. Compared to DQN, this means that we do *not* perform an update step at every environment step, but only at the end of each episode. This means that we should generate an episode of data, compute the REINFORCE loss (which requires computing the returns) and then perform a gradient step.\n",
    "\n",
    "* You can use `torch.multinomial` to sample from a categorical distribution.\n",
    "* The REINFORCE loss is defined as $- \\sum_t \\log \\pi_\\theta(a_t|s_t) G_t$, which means that you should compute the (discounted) return $G_t$ for all $t$. Make sure that you do this in **linear time**, otherwise your algorithm will be very slow! Note the - (minus) since you want to maximize return while you want to minimize the loss.\n",
    "\n",
    "To help you, we wrote down signatures of a few helper functions. Start by implementing a sampling routine that samples a single episode (similarly to the one in Monte Carlo lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to pg_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a pg_autograde.py\n",
    "\n",
    "def sample_episode(env, policy):\n",
    "    \"\"\"\n",
    "    A sampling routine. Given environment and a policy samples one episode and returns states, actions, rewards\n",
    "    and dones from environment's step function as tensors.\n",
    "\n",
    "    Args:\n",
    "        env: OpenAI gym environment.\n",
    "        policy: A policy which allows us to sample actions with its sample_action method.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of tensors (states, actions, rewards, dones). All tensors should have same first dimension and \n",
    "        should have dim=2. This means that vectors of length N (states, rewards, actions) should be Nx1.\n",
    "        Hint: Do not include the state after termination in states.\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    dones = []\n",
    "    \n",
    "\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        \n",
    "        action = policy.sample_action(torch.tensor(state, dtype=torch.double).float())\n",
    "        s_next, r, done, _ = env.step(action)\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        rewards.append(r)\n",
    "        dones.append(done)\n",
    "        state = s_next\n",
    "        \n",
    "        if dones[-1] == True:\n",
    "            break\n",
    "    states = torch.tensor(states).double()\n",
    "    actions = torch.tensor(actions).unsqueeze(1)\n",
    "    rewards = torch.tensor(rewards).unsqueeze(1).double()\n",
    "    dones = torch.tensor(dones).unsqueeze(1)\n",
    "    \n",
    "#     print(states.shape)\n",
    "#     print(actions.shape)\n",
    "#     print(rewards.shape)\n",
    "        \n",
    "    return states, actions, rewards, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jordan/miniconda3/envs/rl2020/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# Let's sample some episodes\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "num_hidden = 128\n",
    "torch.manual_seed(1234)\n",
    "policy = NNPolicy(num_hidden)\n",
    "for episode in range(3):\n",
    "    trajectory_data = sample_episode(env, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement loss computation and training loop of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3f6e32c4931392bf",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to pg_autograde.py\n"
     ]
    }
   ],
   "source": [
    "%%execwritefile -a pg_autograde.py\n",
    "\n",
    "def compute_reinforce_loss(policy, episode, discount_factor):\n",
    "    \"\"\"\n",
    "    Computes reinforce loss for given episode.\n",
    "\n",
    "    Args:\n",
    "        policy: A policy which allows us to get probabilities of actions in states with its get_probs method.\n",
    "\n",
    "    Returns:\n",
    "        loss: reinforce loss\n",
    "    \"\"\"\n",
    "    # Compute the reinforce loss\n",
    "    # Make sure that your function runs in LINEAR TIME\n",
    "    # Note that the rewards/returns should be maximized \n",
    "    # while the loss should be minimized so you need a - somewhere\n",
    "    \n",
    "    states, actions, rewards, dones = episode\n",
    "    \n",
    "    G = [0]\n",
    "    \n",
    "    for r in rewards.flip([1]):\n",
    "        G.append(r+discount_factor*G[-1])\n",
    "    G = torch.FloatTensor(G[1:][::-1])\n",
    "                 \n",
    "    p = policy.get_probs(episode[0].float(),torch.tensor(episode[1]))\n",
    "    \n",
    "    loss = -1 * torch.matmul(G.unsqueeze(0), torch.log(p))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError\n",
    "\n",
    "def run_episodes_policy_gradient(policy, env, num_episodes, discount_factor, learn_rate, \n",
    "                                 sampling_function=sample_episode):\n",
    "    optimizer = optim.Adam(policy.parameters(), learn_rate)\n",
    "    \n",
    "    episode_durations = []\n",
    "    for i in range(num_episodes):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        episode = sample_episode(env, policy)\n",
    "        \n",
    "        loss = compute_reinforce_loss(policy, episode, discount_factor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                           \n",
    "        if i % 10 == 0:\n",
    "            print(\"{2} Episode {0} finished after {1} steps\"\n",
    "                  .format(i, len(episode[0]), '\\033[92m' if len(episode[0]) >= 195 else '\\033[99m'))\n",
    "        episode_durations.append(len(episode[0]))\n",
    "        \n",
    "    return episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing function for nicer plots\n",
    "def smooth(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 0 finished after 24 steps\n",
      "\u001b[99m Episode 10 finished after 10 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jordan/miniconda3/envs/rl2020/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[99m Episode 20 finished after 12 steps\n",
      "\u001b[99m Episode 30 finished after 12 steps\n",
      "\u001b[99m Episode 40 finished after 18 steps\n",
      "\u001b[99m Episode 50 finished after 22 steps\n",
      "\u001b[99m Episode 60 finished after 14 steps\n",
      "\u001b[99m Episode 70 finished after 15 steps\n",
      "\u001b[99m Episode 80 finished after 11 steps\n",
      "\u001b[99m Episode 90 finished after 28 steps\n",
      "\u001b[99m Episode 100 finished after 48 steps\n",
      "\u001b[99m Episode 110 finished after 54 steps\n",
      "\u001b[99m Episode 120 finished after 42 steps\n",
      "\u001b[99m Episode 130 finished after 24 steps\n",
      "\u001b[99m Episode 140 finished after 25 steps\n",
      "\u001b[99m Episode 150 finished after 29 steps\n",
      "\u001b[99m Episode 160 finished after 151 steps\n",
      "\u001b[99m Episode 170 finished after 50 steps\n",
      "\u001b[99m Episode 180 finished after 88 steps\n",
      "\u001b[99m Episode 190 finished after 28 steps\n",
      "\u001b[99m Episode 200 finished after 138 steps\n",
      "\u001b[99m Episode 210 finished after 39 steps\n",
      "\u001b[99m Episode 220 finished after 148 steps\n",
      "\u001b[99m Episode 230 finished after 47 steps\n",
      "\u001b[99m Episode 240 finished after 150 steps\n",
      "\u001b[99m Episode 250 finished after 107 steps\n",
      "\u001b[99m Episode 260 finished after 79 steps\n",
      "\u001b[99m Episode 270 finished after 188 steps\n",
      "\u001b[99m Episode 280 finished after 161 steps\n",
      "\u001b[99m Episode 290 finished after 58 steps\n",
      "\u001b[92m Episode 300 finished after 197 steps\n",
      "\u001b[92m Episode 310 finished after 322 steps\n",
      "\u001b[92m Episode 320 finished after 419 steps\n",
      "\u001b[99m Episode 330 finished after 162 steps\n",
      "\u001b[99m Episode 340 finished after 90 steps\n",
      "\u001b[99m Episode 350 finished after 184 steps\n",
      "\u001b[99m Episode 360 finished after 88 steps\n",
      "\u001b[99m Episode 370 finished after 53 steps\n",
      "\u001b[99m Episode 380 finished after 114 steps\n",
      "\u001b[92m Episode 390 finished after 296 steps\n",
      "\u001b[92m Episode 400 finished after 231 steps\n",
      "\u001b[92m Episode 410 finished after 312 steps\n",
      "\u001b[92m Episode 420 finished after 246 steps\n",
      "\u001b[92m Episode 430 finished after 244 steps\n",
      "\u001b[92m Episode 440 finished after 198 steps\n",
      "\u001b[92m Episode 450 finished after 292 steps\n",
      "\u001b[99m Episode 460 finished after 161 steps\n",
      "\u001b[99m Episode 470 finished after 185 steps\n",
      "\u001b[92m Episode 480 finished after 500 steps\n",
      "\u001b[92m Episode 490 finished after 390 steps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f03580b0a58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feel free to play around with the parameters!\n",
    "num_episodes = 500\n",
    "discount_factor = 0.99\n",
    "learn_rate = 0.001\n",
    "seed = 42\n",
    "env = gym.envs.make(\"CartPole-v1\")\n",
    "torch.manual_seed(seed)\n",
    "env.seed(seed)\n",
    "policy = NNPolicy(num_hidden)\n",
    "\n",
    "episode_durations_policy_gradient = run_episodes_policy_gradient(\n",
    "    policy, env, num_episodes, discount_factor, learn_rate)\n",
    "\n",
    "plt.plot(smooth(episode_durations_policy_gradient, 10))\n",
    "plt.title('Episode durations per episode')\n",
    "plt.legend(['Policy gradient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test/submit your solution **restart the kernel, run all cells and submit the pg_autograde.py file into codegrade.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
